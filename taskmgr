#!/usr/bin/env python
# -*- coding: UTF-8 -*-

# needed to properly import tasks, and to access internal fabric functionality
from fabric import main as fabricmain 
from fabric import network as fabricnetwork
from fabric.api import *

import paramiko

import utils.log
import argparse
import logging
import configparser
import os.path
import sys
import os
import time
import subprocess
import re
import signal
import getpass

import multiprocessing
import Queue


__version__ = "0.5.0"

class OperationException(Exception):
    pass

class ParseException(Exception):
    pass

class TaskRunException(Exception):
    pass

class NoSuchTaskException(Exception):
    pass

class StopException(Exception):
    pass

class TaskMgr(object):

    def __init__(self):
        # read cli arguments
        self.args = self.parse_cli_args()
        self.config = dict()
        self.worker_pools = list()
        self.ssh_config = None

    def get_arguments(self):
        return self.args

    def read_configuration(self, configfile, ctype, allow_no_value=False):
        config = configparser.ConfigParser(allow_no_value=allow_no_value)
        config._interpolation = configparser.ExtendedInterpolation()
        try:
            config.read(configfile)
        except Exception as e:
            raise OperationException("Failed to read type '%s' config file %s: %s" % (ctype, configfile, str(e)))
        self.config[ctype] = config._sections

    def read_commands_file(self, configfile, ctype):
        """
        A simple replacement for configparser, because commands.ini has a different syntax, and ConfigParser
        in python 2.7 doesn't allow to change the delimiter when parsing a config file
        This will read every line in each section and return them within a dict, key names are the sections, values are lists of the lines
        This allows handling lines which are exactly the same (if one goes crazy with the configuration)
        """
        if not os.path.exists(configfile):
            handle_exception("Provided commands file '%s' doesn't exist!" % configfile)
        section = None
        config = dict()
        with open(configfile) as f:
            for line in f:
                line = line.rstrip()
                if re.search("^[#;]", line):
                    continue
                if re.search("^\s*$", line):
                    continue
                m = re.search("^\[([^\]]+)]\s*$", line)
                if m:
                    section = m.group(1)
                    continue
                else:
                    if section is None:
                        raise OperationException("Can't parse config file '%s': data without section has been found." % 'configfile')
                    else:
                        if not section in config.keys():
                            config[section] = list()
                        # store every line as keys, value is None, as we don't have key/value pairs
                        config[section].append(line)
        self.config[ctype] = config

    def get_configuration(self, ctype):
        return self.config[ctype]
    
    def parse_cli_args(self):
        # parse command line arguments
        parser = argparse.ArgumentParser()
        parser.add_argument("-v", "--version", action="version", version=__version__)
        parser.add_argument("--cluster-config", help="The location of the cluster configuration file", default="cluster.ini")
        parser.add_argument("--command-config", help="The location of the cluster configuration file", default="commands.ini")
        parser.add_argument("-H", "--hosts-file", help="File storing the hosts to work on, one by line. If not used, the hostnames from cluster.ini are used.") # fixme
        parser.add_argument("-n", "--cluster-name", help="The name of the cluster to work on. Can be provided multiple times.", action='append', required=True)
        parser.add_argument("-c", "--command", help="THe name of the command to run", required=True)
        parser.add_argument("-d", "--debug", help="Show debug information", action="store_true", default=False)
        parser.add_argument("-x", "--unsafe", help="Enable unsafe operation. (disable host key checking, etc)", action='store_true', default=False)
        parser.add_argument("--show-exception", help="Show exception when tasks fail", action='store_true', default=False)
        parser.add_argument("--ssh-config", help="The ssh configuration file to use.", default="%s/.ssh/config" % os.environ["HOME"])
        parser.add_argument("-f", "--force", help="Use force, like not asking confirmation for custom commands", action="store_true", default=False)

        args = parser.parse_args()
        return args

    def append_worker_pool(self, pool):
        self.worker_pools.append(pool)

    def get_worker_pools(self):
        return self.worker_pools

    def get_node_list_for_cluster(self, cluster):

        # check if the cluster definition exists
        if not cluster in self.config["cluster"].keys():
            handle_exception("Configuration in '%s' for cluster '%s' doesn't exist!" % (self.args.cluster_config, cluster))

        # check if a hostlist was provided
        if not self.args.hosts_file:
            # not provided, use the hostnames defined in cluster.ini
            hosts = subprocess.Popen(["/bin/bash", "-c", "echo %s" % self.config["cluster"][cluster]['hosts']], stdout=subprocess.PIPE).communicate()[0].rstrip().split(" ")
        else:
            # get the hosts from the host file which are matching the pattern given for the current cluster in cluster.ini
            # expand the expression found in cluster.ini using bash - might need to rewrite this in pure python?
            hosts = list()
            try:
                f = open(self.args.hosts_file)
                for host in f.readlines():
                    if re.search("(^\s*$|^#)", host):
                        continue
                    if re.search(self.config["cluster"][cluster]["pattern"], host, flags=re.IGNORECASE):
                        hosts.append(host.rstrip())
            except Exception as e: 
                handle_exception("Problem while reading host file '%s': %s" % (self.args.hosts_file, str(e)))
        return hosts

    def get_full_node_list(self):
        hosts = list()
        for cluster in sorted(self.args.cluster_name):
            hosts.append(self.get_node_list_for_cluster(cluster))
        # return a flattened list (instead of lists of lists)
        return sorted([item for sublist in hosts for item in sublist])


    def read_ssh_config(self):
        self.ssh_config = paramiko.config.SSHConfig()
        self.ssh_config.parse(file(self.args.ssh_config))

    def lookup_ssh_config_for_host(self, hostname):
        if self.ssh_config is None:
            self.read_ssh_config()
        return self.ssh_config.lookup(hostname)

    def get_ssh_users(self):
        """ 
        Go through the ssh cofig file and detect what users are used for connacting hosts
        This will be needed to collect all the necessary passwords in advance
        """
        usernames = list()
        with open(self.args.ssh_config) as f:
            for line in f:
                m = re.search("User ([^ ]+)", line, re.IGNORECASE)
                if m:
                    usernames.append(m.group(1).rstrip())
        # while returning get rid of duplicates
        return sorted(set(usernames))

def handle_exception(exception, *args, **kwargs):
    global pid
    if "fatal" in kwargs.keys():
        fatal = kwargs["fatal"]
    else:
        fatal = True
    
    l.critical(exception, *args)
    
    if os.getpid() == pid:
        # this is the parent process, do cleanup
        if fatal:
            exit_handler(1)
    else:
        # child process
        exit_if_fatal(fatal)

def exit_if_fatal(fatal=True):
    if fatal:
        # close fabric ssh connections
        fabricnetwork.disconnect_all()
        sys.exit(1)



def exit_handler(exit_code=None):
    global taskmgr
    for async_worker in taskmgr.get_worker_pools():
        # finish processing jobs, close queues
        async_worker.finish()
        async_worker.close_queues()

    # close fabric ssh connections
    fabricnetwork.disconnect_all()

    if exit_code is None or exit_code == 0:
        results_flat, results_ok, results_failed = print_statistics()
        
        if exit_code is None:
            if len(results_failed):
                exit_code = 1
            else:
                exit_code = 0
                l.info("")
                l.info("All was OK!")
    sys.exit(exit_code)

def print_statistics():
    global taskmgr
    results = dict()
    actual_list = list()

    for async_worker in taskmgr.get_worker_pools():
        while not async_worker.result_queue_empty():
            host, cluster, result = async_worker.result_queue_get(block=True)
            if not cluster in results:
                results[cluster] = dict()
            results[cluster][host] = result
            actual_list.append(host)

    results_flat = [host for cluster in results.itervalues() for host in cluster.itervalues()]
    results_ok = [i for i in results_flat if i == True]
    results_failed = [i for i in results_flat if i == False]

    # fixme: print the list of nodes that were not executed, using a diff of the two lists
    expected_list = taskmgr.get_full_node_list()
    # get the difference of the expected and the actual lists
    # danger: this will kill ordering (ok), and remove unique elements (should be ok, one host should only be part of one cluster)
    skipped_list = sorted(list(set(expected_list) - set(actual_list)))

    if len(results_flat) > 0:
        l.info("=" * 80)
        l.info("Statistics: ")
        l.info("")
        l.info("Expected: %d" % len(expected_list))
        l.info('Total: %d' % len(results_flat))
        l.info('OK: %d/%0.2f%% |  Failed: %d/%0.2f%%' % (len(results_ok), float(len(results_ok))/float(len(results_flat))*100, len(results_failed), float(len(results_failed))/float(len(results_flat))*100))
        if len(results_failed):
            l.info("")
            l.info("-" * 60)
            l.info("Failed hosts:")
            for cluster in sorted(results.keys()):
                for host in sorted(results[cluster].keys()):
                    if results[cluster][host] == False:
                        l.info("%s / %s" % (cluster, host))
        if len(skipped_list):
            l.info("")
            l.info("-" * 60)
            l.info("Skipped hosts:")
            for host in skipped_list:
                l.info(host)

    return (results_flat, results_ok, results_failed)

def worker(host, cluster, config, args):
    """ The worker function. This is the code that gets executed for each cluster/node combination.
        The final result will represent the success or the failure of the given command on the given machine
        In case of a problem an exception is raised.
    """
    global timeout
    global command_timeout

    # set timeout values for facter
    env.timeout = timeout
    env.command_timeout = command_timeout
    env.abort_on_prompts = True
    env.use_ssh_config = True
    if args.unsafe:
        env.disable_known_hosts = True
        env.reject_unknown_hosts = False
        env.skip_bad_hosts = False
    else:
        env.disable_known_hosts = False
        env.reject_unknown_hosts = True
        env.skip_bad_hosts = True

    # set the password for the given user in env.passwords
    ssh_config = taskmgr.lookup_ssh_config_for_host(host)
    try:
        ssh_port = ssh_config["port"]
    except:
        ssh_port = 22
    try:
        ssh_user = ssh_config["user"]
    except:
        ssh_user = getpass.getuser()

    env.passwords['%s@%s:%s' % (ssh_user, host, ssh_port)] = passwords[ssh_user]

    # ignore ctrl c here
    signal.signal(signal.SIGINT, signal.SIG_IGN)

    # command1: segment1 segment2 segment3
    # command2: segment1 segment2 segment3
    for command in config["command"][args.command]:

        # there are two types of input in commands.ini:
        # 1) check|wait|execute [not] command[:arguments] [skip|stop] (default: stop)
        # 2) check|wait|execute [not] cmd:task.name:arguments [cmd:task.name2:arguments] [skip|stop,all|any]

        # parse these two differently
        # check if 2) matches (:cmd)
        erroraction = "stop"
        multiple = True
        negate = None
        if not command.find(" cmd:") == -1:
            # type 2)
            cmd_name = "direct"

            m = re.search("^([^ ]+)(?: (not))?( cmd:[^\]]+)(?: \[([^\]]+)])?\s*$", command)
            if m:
                action = m.group(1)
                negate = m.group(2)
                tmp_command = m.group(3)
                flags = m.group(4)
                if not flags is None:
                    flags = flags.split(",")
                    if "skip" in flags:
                        erroraction = "skip"
                    if "stop" in flags:
                        erroraction = "stop"
                    if "skip" in flags and "stop" in flags:
                        handle_exception("Providing both 'skip' and 'stop' flags doesn't make any sense! (%s: %s)" % (args.command, command), host, cluster)
                    if "all" in flags:
                        multiple = True
                    if "any" in flags:
                        multiple = False
                    if "any" in flags and "all" in flags:
                        handle_exception("Providing both 'any' and 'all' flags doesn't make any sense! (%s: %s)" % (args.command, command), host, cluster)

            else:
                handle_exception("Can't parse command '%s/%s'" % (args.command, command), host, cluster)

            if negate is None:
                negate = False
            elif negate == "not":
                negate = True

            cmd_segments = filter(bool, re.split(" ?cmd:", tmp_command, flags=re.IGNORECASE))

        else:
            # type 1)            
            m = re.search("^(check|wait|execute)(?: (not))? ([^ :]+)(?::(.+))?(?: \[(skip|stop)\])?$", command)
            if m:
                action, negate, cmd_name, cmd_arguments, erroraction = m.groups()
            else:
                raise AttributeError("Can't parse the command definition for command '%s' in '%s'" % (command, args.command_config), host, cluster)
    
            if erroraction is None:
                erroraction = "stop"
            
            if negate is None:
                negate = False
            elif negate == "not":
                negate = True
    
            erroractions_available = ["stop", "skip"]
            if not erroraction in erroractions_available:
                handle_exception("Error action '%s' for command '%s/%s %s' is unknown. Please use either of: %s" % (erroraction, args.command, action, cmd_name, ",".join(erroractions_available)))
        
            # check if a counterpart in cluster.ini exists
            # pair the check name with the one that is defined in the cluster configuration
            if not cmd_name in config['cluster'][cluster]:
                handle_exception("Referenced command '%s' is not defined in in '%s' for cluster '%s'!" % (cmd_name, args.cluster_config, cluster), host, cluster)
        
            # run the check, fail if result is false
            # remove all|any form the end
    
            # split the command on 'cmd:'
            # check if ' (all|any)$' matches the command
            tmp_command = config["cluster"][cluster][cmd_name]

            # if arguments are passed from commands.ini, add them to tmp_command 
            if not cmd_arguments is None:
                tmp_command = tmp_command.replace('%ARGS%', cmd_arguments)

            # sanity check
            try:
                i = tmp_command.index('%ARGS%')
                raise ValueError("Placeholder '%ARGS%' is used for command '%s', but no arguments are passed from '%s'!" % (cmd_name, args.command_config), host, cluster)
            except:
                pass
    
            m = re.search("^(.*) (any|all)$", tmp_command, flags=re.IGNORECASE)
            if m:
                # found, set multiple, and remove it from the end of the string
                tmp_command = m.group(1)
                if m.group(2) == "all":
                    multiple = True
                elif m.group(2) == "any":
                    multiple = False
                else:
                    handle_exception("Syntax error for command '%s' in '%s' for cluster '%s': multiple must be either 'all' or 'any'" % (cmd_name, args.cluster_config, cluster), host, cluster)
            else:
                # default is 'all'
                multiple = True
    
            # split commands on 'cmd:', and filter out any empty elements
            cmd_segments = filter(bool, re.split(" ?cmd:", tmp_command, flags=re.IGNORECASE))

        # call the commands
        # rule of thumb: on any failed check we return with false, meaning that the command failed
        # iterate on the segments, process them one by one
        if action == "check":
            try:
                result = run_check_tasks(host, cluster, cmd_name, cmd_segments, multiple)
                if negate:
                    result = not result
            except Exception as e:
                raise
            if not result:
                l.error("%s '%s' failed" % (action, cmd_name), host, cluster)
                if erroraction == "skip":
                    l.warning("Error action for %s '%s' is 'skip', moving on with next host" % (action, cmd_name), host, cluster)
                    return (host, cluster, False)
                elif erroraction == "stop":
                    raise StopException("Requested action for %s %s on %s/%s is '%s'" %(action, cmd_name, cluster, host, erroraction))
            else:
                l.info("%s '%s' OK" % (action, cmd_name), host, cluster)
        
        elif action == "wait":
            # stop and wait until check returns true
            try:
                result = run_wait_tasks(host, cluster, cmd_name, cmd_segments, multiple, negate)
            except Exception as e:
                raise
            if not result:
                # for this we would need to implement timeouts in run_wait_tasks, because right now False is never returned
                # in this case will need to evaluate 'erroraction' 
                l.error("%s '%s' failed" % (action, cmd_name), host, cluster)
                return (host, cluster, False)
            else:
                l.info("%s '%s' OK" % (action, cmd_name), host, cluster)
        
        elif action == "execute":
            try:
                result = run_execute_tasks(host, cluster, cmd_name, cmd_segments, multiple)
                if negate:
                    result = not result
            except Exception as e:
                raise
            if not result:
                l.error("%s '%s' failed" % (action, cmd_name), host, cluster)
                if erroraction == "skip":
                    l.warning("Error action for %s '%s' is 'skip', moving on with next host, but not stopping" % (action, cmd_name), host, cluster)
                    return (host, cluster, False)
                elif erroraction == "stop":
                    raise StopException("Requested action for %s %s on %s/%s is '%s'" %(action, cmd_name, cluster, host, erroraction))
            else:
                l.info("%s '%s' OK" % (action, cmd_name), host, cluster)

        else:
            handle_exception("Unknown command '%s' defined in '%s'!" % (cmd_name, args.command_config), host, cluster)    

    l.important("All commands for %s/%s have been successfully run" % (cluster, host), host, cluster)
    return (host, cluster, True)

def run_check_tasks(host, cluster, cmd_name, cmd_segments, multiple):
    """ 
        A helper task called from worker() to execute a check task
    """
    global timeout
    global command_timeout
    global callables
    results = list()
    for cmd in cmd_segments:
        check_name = cmd.split(":")[0].rstrip()
        check_arguments = ":".join(cmd.split(":")[1:]).rstrip()
        if not check_name in fabricmain._task_names(callables):
            raise NoSuchTaskException("Fabric task '%s' doesn't exist!" % check_name)

        try: 
            l.debug("Executing check %s: '%s %s'" % (cmd_name, check_name, check_arguments), host, cluster)
            with quiet():
                result = execute(check_name, check_arguments, cluster, hosts=[host])
        except Exception as e:
            raise TaskRunException("Failed to run fabric task '%s' on host '%s' (cluster '%s'): %s" % (check_name, host, cluster, str(e)))

        # got the result, good
        if multiple:
            if result[host]:
                results.append(result[host])
                continue
            else:
                return False
        else:
            if result[host]:
                return True
            else:
                continue
                results.append(result[host])
    # if we are here all of the checks have been run
    # either because multiple is True, or because multiple is False, but
    # the first checks failed
    if multiple:
        return all(res == True for res in results)
    else:
        return any(res == True for res in results)

def run_wait_tasks(host, cluster, cmd_name, cmd_segments, multiple, negate):
    """ 
    A helper task called from worker() to execute a wait task
    """
    global timeout
    global command_timeout
    global callables

    results = list()

    for cmd in cmd_segments:
        check_name = cmd.split(":")[0].rstrip()
        check_arguments = ":".join(cmd.split(":")[1:]).rstrip()
        # check if a given fabric task exists
        if not check_name in fabricmain._task_names(callables):
            raise NoSuchTaskException("Fabric task '%s' doesn't exist!" % check_name)

        l.debug("Starting wait %s: '%s %s' returns..." % (cmd_name, check_name, check_arguments), host, cluster)
        while True:
            # this loop is needed to ensure we wait until the check is finally ok
            try:
                l.debug("Executing wait %s: '%s %s'" % (cmd_name, check_name, check_arguments), host, cluster)
                with quiet():             
                    result = execute(check_name, check_arguments, cluster, hosts=[host])
                    if negate:
                        result[host] = not result[host]
            except Exception as e:
                raise TaskRunException("Failed to run fabric task '%s' on host '%s' (cluster '%s'): %s" % (check_name, host, cluster, str(e)))
            if result[host] == True:
                # break out of while True
                l.debug("Got response, moving on", host, cluster)
                break
            else:
                # failed, have to wait longer
                l.debug("Waiting before retrying", host, cluster)
                time.sleep(5)
                continue
        # we are here, so there was a successful result
        if multiple == False:
            # we can return at this point
            return True
        else:
            results.append(True)
        if not len(results) < len(cmd_segments):
            break
    # if we are here:
    #   * multiple is true
    #   * all waits have finished with success, no need to evaluate results
    return True

def run_execute_tasks(host, cluster, cmd_name, cmd_segments, multiple):
    """ 
        A helper task called from worker() to execute an 'execute' task
    """
    global timeout
    global command_timeout
    global callables
    results = list()
    for cmd in cmd_segments:
        check_name = cmd.split(":")[0].rstrip()
        check_arguments = ":".join(cmd.split(":")[1:]).rstrip()
        if not check_name in fabricmain._task_names(callables):
            raise NoSuchTaskException("Fabric task '%s' doesn't exist!" % check_name)

        try: 
            l.debug("Executing %s: '%s %s'" % (cmd_name, check_name, check_arguments), host, cluster)
            with quiet():
                result = execute(check_name, check_arguments, cluster, hosts=[host])
        except Exception as e:
            raise TaskRunException("Failed to run fabric task '%s' on host '%s' (cluster '%s'): %s" % (check_name, host, cluster, str(e)))

        # got the result, good
        if multiple:
            if result[host]:
                results.append(result[host])
                continue
            else:
                return False
        else:
            if result[host]:
                return True
            else:
                continue
                results.append(result[host])
    # if we are here all of the checks have been run
    # either because multiple is True, or because multiple is False, but
    # the first checks failed
    if multiple:
        return all(res == True for res in results)
    else:
        return any(res == True for res in results)


# due to a possible bug in the signal handling of multiprocessing's Pool implementation
# we need our own pool management
# http://bryceboe.com/2010/08/26/python-multiprocessing-and-keyboardinterrupt/
class AsyncWorker:
    def __init__(self):
        self.job_queue = multiprocessing.Queue()
        self.result_queue = multiprocessing.Queue() 
        self.workers = list()
        self.failed_clusters = dict()
        #self.failed_nodes = dict()
        #self.lock = multiprocessing.Lock()

    def add_job(self, host, cluster, config, args):
        self.job_queue.put((host, cluster, config, args))

    def start_workers(self, worker_func, max_parallel):
        for i in range(max_parallel):
            w = multiprocessing.Process(target=self._worker_helper, args=(worker_func,))
            w.daemon = True
            w.start()
            self.workers.append(w)

    def _worker_helper(self, worker_func):
        while not self.job_queue.empty():
            try:
                host, cluster, config, args = self.job_queue.get(block=False)

                # implement failing policy:
                # we don't allow any more jobs for faulty nodes
                # but we allow other nodes to finish
                # we don't start any new nodes
                # flags are set in the exception handling part
                if cluster in self.failed_clusters.keys():
                    if self.failed_clusters[cluster]['!alerted!'] == False:
                        l.error("Due to previous errors, new nodes on cluster '%s' are not processed. Already running tasks are allowed to finish." % cluster, host, cluster)
                        self.failed_clusters[cluster]['!alerted!'] = True
                    if host in self.failed_clusters[cluster].keys():
                        if self.failed_clusters[cluster][host] == False:
                            # first occurance, notify
                            l.error("Due to previous errors, no more tasks on '%s/%s' are executed as of now." % (cluster, host), host, cluster)
                            self.failed_clusters[cluster][host] = True
                            continue
                        else:
                            l.warning("skipping instead of starting")
                            continue
                    else:
                        # in the marked cluster, but not marked host, don't allow to continue
                        continue
                else:
                    # not marked cluster, allow to continue
                    pass

                # if here, start the task
                self.result_queue.put(worker_func(host, cluster, config, args)) # put the results to the queue

            except Queue.Empty:
                pass
            except KeyboardInterrupt:
                pass
            except Exception as e:

                if args.show_exception:
                    l.exception(e, host, cluster)

                # this indicates that a vital task has failed (erroraction==stop)
                # or in case there was only one check at a command, then that one check failed
                # in this case put a result entry in the queue
                self.result_queue.put((host, cluster, False))
                
                # add the given cluster/node to the faulty clusters list
                # mark the cluster as faulty by creating the cluster key if it doesn't already exist
                if not cluster in self.failed_clusters.keys():
                    self.failed_clusters[cluster] = dict()
                    self.failed_clusters[cluster]["!alerted!"] = False

                # mark the node as faulty by adding it to the dict
                # False means that it has not been notified yet
                # after notification flag will be turned true to avoid re-notification
                if not host in self.failed_clusters[cluster].keys():
                    self.failed_clusters[cluster][host] = False

    def wait(self):
        for worker in self.workers:
            worker.join()

    def finish(self):
        for worker in self.workers:
            worker.terminate()
            worker.join()

    def result_queue_empty(self):
        return self.result_queue.empty()

    def result_queue_get(self, block=False):
        return self.result_queue.get(block)

    def close_queues(self):
        while not self.job_queue.empty():
            self.job_queue.get()
        self.job_queue.close()


###################################################################################3

# global variable holding logger object
#l = object
taskmgr = object
# timeouts to use
timeout = 10
command_timeout = None
pid = os.getpid()
passwords = dict()

# load available fabric task files 
# http://stackoverflow.com/questions/23605418/in-fabric-how-can-i-execute-tasks-from-another-python-file
docstring, callables, default = fabricmain.load_fabfile('fabfile')
fabricmain.state.commands.update(callables)

# initialize logger
try:
    format_file = '%(asctime)s %(clusterinfo)s - %(levelname)s - %(message)s'
    format_console = '$COLOR%(clusterinfo)s%(levelname)s - %(message)s'
    l = utils.log.initialize_logger('taskmgr.log', format_file, format_console)
except Exception as e:
    print "Can't initialize logger: ", str(e)
    sys.exit(1)

if __name__ == '__main__':

    config = dict()

    # create taskmanager object
    taskmgr = TaskMgr()
    args = taskmgr.get_arguments()

    # set the loglevel based on args.debug
    if args.debug:
        loglevel = logging.DEBUG
    else:
        loglevel = logging.INFO
    #l.setLevel(loglevel)
    logging.getLogger().setLevel(loglevel)
    
    # make paramiko shut up
    logging.getLogger("paramiko").setLevel(logging.CRITICAL)

    # parse the cluster configuration
    try:
        taskmgr.read_configuration(args.cluster_config, ctype="cluster")
    except OperationException as e:
        handle_exception(e)
    # get the parsed configuration in the form of a dict
    config["cluster"] = taskmgr.get_configuration("cluster")

    # parse the command configuration
    try:
        taskmgr.read_commands_file(args.command_config, ctype="command")
    except OperationException as e:
        handle_exception(e)
    # get the parsed configuration in the form of a dict
    config["command"] = taskmgr.get_configuration("command")

    if not args.command in config["command"].keys():
        handle_exception("Configuration in '%s' for command '%s' doesn't exist!" % (args.command_config, args.command))

    # look at the parsed commands file for the requested command, and check for custom_cmd entries.
    # if found, print them and ask for user confirmation (unless --force is used) before continuing
    if not args.force:
        custom_cmds = list()
        for cmd in config["command"][args.command]:
            if re.search("custom_cmd", cmd):
                m = re.search("^([^ ]+)(?: (not))?( cmd:[^\]]+)(?: \[([^\]]+)])?\s*$", cmd)
                if m:
                    cmd_segments = filter(bool, re.split(" cmd:[^:]+:", m.group(3), flags=re.IGNORECASE))
                    for segment in cmd_segments:
                        with quiet():
                            l.debug("calling with: %s" % segment)
                            custom_cmds.append(execute("execute.custom_cmd.parse", segment, host="localhost")["localhost"][1])
                else:
                    # ask question, can't parse, might mean problems
                    l.warning("Custom_cmd found, but failed to parse line.")
                    custom.cmds.append(None)
        if len(custom_cmds):
            # there was at least custom command, or unparseable line

            # get rid of unique elements
            custom_cmds = set(custom_cmds)
            l.warning("Warning: The following custom commands have been found that will be executed: ")
            print ""
            for cmd in custom_cmds:
                print cmd
            print ""
            while True:
                answer = raw_input("Are you sure you want to continue? [y/N]").rstrip("\n")
                if not answer:
                    l.info("User abort, exiting.")
                    print ""
                    sys.exit(1)
                if answer == "y":
                    l.info("User answered yes, going on")
                    print ""
                    break

    if not os.path.exists(args.ssh_config):
        handle_exception("Provided ssh config file '%s' doesn't exist!" % args.ssh_config)

    # count how many machines will be processed - for statistics later on
    nodelist = taskmgr.get_full_node_list()

    # read the passwords for all users defined in ssh_config
    # fabric would do this, but because of parallel execution it doesn't always work
    users = taskmgr.get_ssh_users()
    if not len(users):
        # no users specified, use the current user
        users.append(getpass.getuser())
    else:
       # read in the password for each user
       for user in users:
            passwords[user] = getpass.getpass("Please provide password for user '%s': " % user)

    # iterate on the provided cluster names
    for cluster in args.cluster_name:

        hosts = taskmgr.get_node_list_for_cluster(cluster)
        ## check if the cluster definition exists
        #if not cluster in config["cluster"].keys():
        #    handle_exception("Configuration in '%s' for cluster '%s' doesn't exist!" % (args.cluster_config, cluster))
        #
        ## check if a hostlist was provided
        #if not args.hosts_file:
        #    # not provided, use the hostnames defined in cluster.ini
        #    hosts = subprocess.Popen(["/bin/bash", "-c", "echo %s" % config["cluster"][cluster]['hosts']], stdout=subprocess.PIPE).communicate()[0].rstrip().split(" ")
        #else:
        #    # get the hosts from the host file which are matching the pattern given for the current cluster in cluster.ini
        #    # expand the expression found in cluster.ini using bash - might need to rewrite this in pure python?
        #    hosts = list()
        #    try:
        #        f = open(args.hosts_file)
        #        for host in f.readlines():
        #            if re.search("(^\s*$|^#)", host):
        #                continue
        #            if re.search(config["cluster"][cluster]["pattern"], host, re.IGNORECASE):
        #                hosts.append(host.rstrip())
        #    except Exception as e: 
        #        handle_exception("Problem while reading host file '%s': %s" % (args.hosts_file, str(e)))

        async_worker = AsyncWorker()
        taskmgr.append_worker_pool(async_worker)

        # launch workers
        for host in hosts:
            async_worker.add_job(host, cluster, config, args)
        
        # launch the workers
        async_worker.start_workers(worker, int(config["cluster"][cluster]["max_parallel"]))

    try:
        for async_worker in taskmgr.get_worker_pools():
            async_worker.wait()
            # close all queues
            async_worker.close_queues()            
    except KeyboardInterrupt:
        print "Received Ctrl + C, exiting..."
        # don't wait, just close queues
        exit_handler(1)
        #for async_worker in taskmgr.get_worker_pools():
        #    # finish processing jobs, close queues
        #    async_worker.finish()
        #    async_worker.close_queues()
        #sys.exit(1)

    # close fabric ssh connections
    fabricnetwork.disconnect_all()

    results_flat, results_ok, results_failed = print_statistics()
    if len(results_flat) and not len(results_failed):
        exit_code = 0
        l.info("")
        l.important("All was OK!")
    else:
        exit_code = 1
    sys.exit(exit_code)
    # print final statistics 
    #results = dict()
    #l.info("=" * 80)
    #l.info("Statistics: ")
    #for async_worker in taskmgr.get_worker_pools():
    #    while not async_worker.result_queue_empty():
    #        host, cluster, result = async_worker.result_queue_get(block=True)
    #        if not cluster in results:
    #            results[cluster] = dict()
    #        results[cluster][host] = result
    #print results
    #results_flat = [host for cluster in results.itervalues() for host in cluster.itervalues()]
    #results_ok = [i for i in results_flat if i == True]
    #results_failed = [i for i in results_flat if i == False]
#
    #l.info('Total: %d' % len(results_flat))
    #l.info('OK: %d/%0.2f%% |  Failed: %d/%0.2f%%' % (len(results_ok), len(results_ok)/len(results_flat)*100, len(results_failed), len(results_failed)/len(results_flat)*100))
    #if len(results_failed):
    #    l.info("")
    #    l.info("-" * 60)
    #    l.info("Failed hosts:")
    #    for cluster in sorted(results.keys()):
    #        for host in results[cluster].keys():
    #            if results[cluster][host] == False:
    #                l.info("%s / %s" % (cluster, host))
    #    sys.exit(1)
    #else:
    #    l.info("")
    #    l.info("All was OK!")
    #    sys.exit(0)

    # todo:
    # child to signal parent if exception to stop feeding new jobs
    # statistics not realistic when check name doesn't exist and check fails because of this
    # review exit_handler and print statistic


